# @package _global_
defaults:
  - override /model: event_wassdiff
  - override /data: latent_custom
  - _self_

trainer:
  max_epochs: 500
  check_val_every_n_epoch: 2

logger:
  wandb:
    project: "Event-WassDiff"
    name:    "Latent-Regressor"

data:
  batch_size: 12
  num_workers: 8

callbacks:
  log_event_data:
    _target_: src.utils.callbacks.event_wandb_logger.EventLogger
    # ───────────────────────────────────────────────────────
    # how often to log training images
    train_log_img_freq: 1
    # how often to log training scalar metrics
    train_log_score_freq: 10
    # how often to snapshot + save a checkpoint (-1 to disable)
    train_ckpt_freq: -1
    sampling_batch_size: 8
  model_checkpoint:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath:   ${paths.output_dir}/checkpoints
    filename:  "epoch_{epoch:03d}"
    monitor:   "val/loss"
    mode:      "min"
    save_top_k: 3
    save_last:  true
