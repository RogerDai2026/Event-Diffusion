# configs/baseline_cordiff_event.yaml
# -----------------------------------------------------------------------------
# Defines just the model (CorrDiffEventLitModule), its UNet, optimizer, loss, sampler
# -----------------------------------------------------------------------------
_target_: src.models.baselines.cnn.corrdiff_unet.CorrDiffEventDiffusionModule

# whether to torch.compile() the net, and resize inputs to multiples of 16
compile: false
allow_resize: true

# ensemble size at test / sample()
num_samples: 1

# -------------------------------------------------------------------
# 1) The core UNet “net” (borrowed from NVIDIA’s physicsnemo)
# -------------------------------------------------------------------
net:
  _target_: physicsnemo.models.diffusion.EDMPrecondSR
  img_channels: 4
  N_grid_channels: 4 # 4# output channels for depth
  img_resolution: [256, 352]
#  embedding_type: "zero"
  checkpoint_level: 0
  img_in_channels: 7
  img_out_channels: 1               # single‐channel depth
  use_fp16: false

# -------------------------------------------------------------------
# 2) Optimize with Adam
# -------------------------------------------------------------------
optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 2e-4
  betas: [0.9, 0.999]
  eps: 1e-8

# -------------------------------------------------------------------
# 3) Two‐stage RegressionLoss (CNN mean + diffusion residual)
# -------------------------------------------------------------------
criterion:
  _target_: src.utils.corrdiff_utils.loss.ResLoss
  _partial_: true
  hr_mean_conditioning: false       # don’t re‐use the mean as extra cond
  img_shape_x: 344
  img_shape_y: 256
  patch_shape_x: 344
  patch_shape_y: 256
  patch_num : 1

# -------------------------------------------------------------------
# 4) Sampler for the diffusion‐residual stage
# -------------------------------------------------------------------
sampling:
  _target_: physicsnemo.utils.generative.stochastic_sampler
  _partial_: true
  boundary_pix: 2
  overlap_pix: 4
  img_shape: [256, 344]
  patch_shape: [256, 344]


regression_model_cfg:
  # you can literally copy the same entries, or interpolate from `net`
  img_channels: 1
  img_resolution: [256, 352]        # your event‐frame H×W
  img_in_channels: ${data.data_config.num_input_chs}
  img_out_channels: 1               # single‐channel depth
  use_fp16: false
  model_type: "SongUNet"